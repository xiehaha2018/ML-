{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 隐马尔可夫链词性标注\n",
    "*具体流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./hmm4.png)\n",
    "![title](./hmm1.png)\n",
    "![title](./hmm2.png)\n",
    "![title](./hmm3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对词进行预处理，给brown中的句子加入start和end标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags_words=[]\n",
    "for sent in brown.tagged_sents():   #tagged_sents表示\n",
    "    brown_tags_words.append(('START','START'))\n",
    "    brown_tags_words.extend([(tag[:2],word) for (word,tag) in sent]) #list.extend()表示在已存在列表中添加新列表内容\n",
    "    brown_tags_words.append(('END','END'))\n",
    "# print(brown_tags_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一步：通过nltk自带函数，统计词库中单词与tag的关系$ P(w_{i}|t_{i})=\\frac{count(w_{i},t_{i})}{count(t_{i})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjective (JJ) being 'new' is 0.01472344917632025\n",
      "The probability of a verb (VB) being 'duck' is 6.042713350943527e-05\n"
     ]
    }
   ],
   "source": [
    " #nltk.ConditionalFreDist表示计算条件‘频率’分布，即count（wi，ti）（输入为元组）\n",
    "cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "\n",
    "#nltk.ConditionalProbDist表示计算tag与words之间的条件‘概率’分布,即p（wi|ti）\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords,nltk.MLEProbDist) \n",
    "\n",
    "# print(cpd_tagwords['NN'].prob('County')) 输出nn是county的概率\n",
    "print(\"The probability of an adjective (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
    "print(\"The probability of a verb (VB) being 'duck' is\", cpd_tagwords[\"VB\"].prob(\"duck\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二步：计算$P(t_{i}|t_{i-1})=\\frac{count(t_{i-1},t_{i})}{count(t_{i-1})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags = [tag for (tag,word) in brown_tags_words] #取出tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算count(ti-1,ti)\n",
    "cfd_tags = nltk.ConditionalFreqDist(nltk.bigrams(brown_tags)) #nltk.bigrams表示将一个列表前后两个一组的元组，排列成list\n",
    "#计算p（ti|ti-1）\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags,nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if we have just seen 'DT',the probability of 'NN' is  0\n",
      "if we have just seen 'VB',the probability of 'JJ' is  0.03443483365273389\n",
      "if we have just seen 'VB',the probability of 'NN' is  0.10970977711020183\n"
     ]
    }
   ],
   "source": [
    "print(\"if we have just seen 'DT',the probability of 'NN' is \",cpd_tags['TD'].prob('NN'))\n",
    "print(\"if we have just seen 'VB',the probability of 'JJ' is \",cpd_tags['VB'].prob('JJ'))\n",
    "print(\"if we have just seen 'VB',the probability of 'NN' is \",cpd_tags['VB'].prob('NN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 举例：‘i want to race',的tag表示为：'PP VB TO VB',看看他们的概率是多少\n",
    "* 分解就是P(START) * P(PP|START) * P(I | PP) *P(VB | PP) * P(want | VB) * P(TO | VB) * P(to | TO) *P(VB | TO) * P(race | VB) *P(END | VB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the tag sequence 'START PP VB TO VB END'for 'i want to race' is: 1.0817766461150474e-14\n"
     ]
    }
   ],
   "source": [
    "prob_tagsquence = cpd_tags['START'].prob('PP')*cpd_tagwords[\"PP\"].prob(\"I\") * \\\n",
    "    cpd_tags[\"PP\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"want\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"TO\") * cpd_tagwords[\"TO\"].prob(\"to\") * \\\n",
    "    cpd_tags[\"TO\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"race\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"END\")\n",
    "print(\"The probability of the tag sequence 'START PP VB TO VB END'for 'i want to race' is:\",prob_tagsquence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi实现\n",
    "* 如果目前有句话，计算最符合的tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_viterbi: {'PP': 0.014930900689060006, 'NI': 3.3324520848931064e-07, 'EX': 0.0, 'CS': 0.0, ')-': 0.0, ',': 0.0, 'RP': 0.0, 'AT': 0.0, ')': 0.0, ',-': 0.0, 'AP': 0.0, 'CC': 0.0, 'IN': 0.0, 'NP': 1.7319067623793952e-06, 'END': 0.0, 'MD': 0.0, 'NR': 0.0, 'BE': 0.0, '*': 0.0, 'VB': 0.0, 'DO': 0.0, 'TO': 0.0, ':-': 0.0, '*-': 0.0, ':': 0.0, 'WR': 0.0, 'WP': 0.0, 'HV': 0.0, \"'\": 0.0, 'DT': 0.0, '.': 0.0, 'WQ': 0.0, 'UH': 0.0, 'PN': 0.0, '--': 0.0, 'CD': 0.0, '(': 0.0, '(-': 0.0, '``': 0.0, \"''\": 0.0, 'AB': 0.0, 'OD': 0.0, 'RN': 0.0, 'WD': 0.0, 'NN': 1.0580313619573935e-06, 'JJ': 0.0, 'RB': 0.0, 'FW': 0.0, '.-': 0.0, 'QL': 0.0}\n",
      "\n",
      "\n",
      "first_backpointer: {'PP': 'START', 'NI': 'START', 'EX': 'START', 'CS': 'START', ')-': 'START', ',': 'START', 'RP': 'START', 'AT': 'START', ')': 'START', ',-': 'START', 'AP': 'START', 'CC': 'START', 'IN': 'START', 'NP': 'START', 'END': 'START', 'MD': 'START', 'NR': 'START', 'BE': 'START', '*': 'START', 'VB': 'START', 'DO': 'START', 'TO': 'START', ':-': 'START', '*-': 'START', ':': 'START', 'WR': 'START', 'WP': 'START', 'HV': 'START', \"'\": 'START', 'DT': 'START', '.': 'START', 'WQ': 'START', 'UH': 'START', 'PN': 'START', '--': 'START', 'CD': 'START', '(': 'START', '(-': 'START', '``': 'START', \"''\": 'START', 'AB': 'START', 'OD': 'START', 'RN': 'START', 'WD': 'START', 'NN': 'START', 'JJ': 'START', 'RB': 'START', 'FW': 'START', '.-': 'START', 'QL': 'START'}\n",
      "\n",
      "\n",
      "word 'I' current best two_tag sequence: START PP\n",
      "\n",
      "\n",
      "word 'want' current best two_tag sequence: PP VB\n",
      "\n",
      "\n",
      "word 'to' current best two_tag sequence: VB TO\n",
      "\n",
      "\n",
      "word 'race' current best two_tag sequence: IN NN\n",
      "\n",
      "\n",
      "the sentece was: I want to race \n",
      "\n",
      "the best tag sequence is: START PP VB IN NN END \n",
      "\n",
      "the probability of the best tag sequence is 5.71772824864617e-14\n"
     ]
    }
   ],
   "source": [
    "#将tags集合化\n",
    "distinct_tags = set(brown_tags)\n",
    "\n",
    "#随意设置一句话\n",
    "sentence = ['I','want','to','race']\n",
    "senlen = len(sentence)\n",
    "\n",
    "#初始化\n",
    "viterbi = []\n",
    "backpointer = []  #回溯器：从1循环到句子的总长n，即为i；把所有tagx前一个tag记下\n",
    "first_viterbi = {}\n",
    "first_backpointer = {}  \n",
    "\n",
    "for tag in distinct_tags:\n",
    "    if tag == 'START':  #'START'不记录跳过\n",
    "        continue\n",
    "    first_viterbi[tag] = cpd_tags['START'].prob(tag)*cpd_tagwords[tag].prob(sentence[0])\n",
    "    first_backpointer[tag] = 'START'\n",
    "\n",
    "print('first_viterbi:',first_viterbi) #第一个viterbi\n",
    "print('\\n')\n",
    "print('first_backpointer:',first_backpointer) #第一个回溯点\n",
    "print('\\n')\n",
    "\n",
    "#将之前的分别存入viterbi和backpointer两个变量\n",
    "viterbi.append(first_viterbi)\n",
    "backpointer.append(first_backpointer)\n",
    "\n",
    "currbest = max(first_viterbi.keys(),key=lambda tag:first_viterbi[tag])  #max()返回最大项\n",
    "print('word',\"'\"+sentence[0]+\"'\",'current best two_tag sequence:',first_backpointer[currbest],currbest) #目前最可能的tag\n",
    "print('\\n')\n",
    "for wordindex in range(1,len(sentence)):\n",
    "    this_viterbi = {}\n",
    "    this_backpointer = {}\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    for tag in distinct_tags:\n",
    "        if tag == 'START':\n",
    "            continue\n",
    "        #假设目前单词为w，tag为x，前一个tag为y，为了找到最好的以y，x结尾的tag，则要最大化prev_viterbi[y]*p(x|y)p(w|x)\n",
    "        best_previous =max(prev_viterbi.keys(),key=lambda prevtag:prev_viterbi[prevtag]*cpd_tags[prevtag].prob(tag)*cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "        this_viterbi[tag]=prev_viterbi[best_previous]*cpd_tags[best_previous].prob(tag)*cpd_tagwords[tag].prob(sentence[wordindex])\n",
    "        this_backpointer[tag]=best_previous\n",
    "    currbest=max(this_viterbi.keys(),key=lambda tag:this_viterbi[tag])\n",
    "    print('word',\"'\"+sentence[wordindex]+\"'\",'current best two_tag sequence:',this_backpointer[currbest],currbest)\n",
    "    print('\\n')\n",
    "    viterbi.append(this_viterbi)\n",
    "    backpointer.append(this_backpointer)\n",
    "    \n",
    "#找到以end结束的tag sequence\n",
    "prev_viterbi = viterbi[-1]\n",
    "#最大化prev_viterbi[y]*p(end|y)\n",
    "best_previous = max(prev_viterbi.keys(),key=lambda prevtag:prev_viterbi[prevtag]*cpd_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "#计算prob_tagsequence=prev_viterbi[best_y]*p(end|best_y)\n",
    "prob_tagsequence = prev_viterbi[best_previous]*cpd_tags[best_previous].prob('END')\n",
    "\n",
    "#存储为倒序，因此backpointer()也要倒过来\n",
    "best_tagsequence = ['END',best_previous]\n",
    "backpointer.reverse()\n",
    "\n",
    "#回溯所有回溯点，最好的tag都对应存储在backpointer中，'end'结尾的最好的tag存储在best_previous中\n",
    "current_best_tag = best_previous\n",
    "for bp in backpointer:\n",
    "    best_tagsequence.append(bp[current_best_tag])\n",
    "    current_best_tag = bp[current_best_tag]\n",
    "    \n",
    "best_tagsequence.reverse()\n",
    "print('the sentece was:',end=' ')\n",
    "for w in sentence: print(w,end=' ')\n",
    "print('\\n')\n",
    "print('the best tag sequence is:',end=' ')\n",
    "for t in best_tagsequence: print(t,end=' ')\n",
    "print('\\n')\n",
    "print('the probability of the best tag sequence is',prob_tagsequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
